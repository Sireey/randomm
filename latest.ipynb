{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "import numpy as np\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_telugu_captions(filepath):\n",
    "    captions_dict = {}\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            img_name, caption = parts[0].split(\"#\")[0], parts[1]\n",
    "            if img_name not in captions_dict:\n",
    "                captions_dict[img_name] = []\n",
    "            captions_dict[img_name].append(caption)\n",
    "    return captions_dict\n",
    "\n",
    "# Convert text to Unicode IDs (Simple Tokenizer Workaround)\n",
    "def text_to_ids(text):\n",
    "    tokens = tokenize_te(text)\n",
    "    token_ids = [ord(char) for token in tokens for char in token]  # Unicode ID mapping\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeluguDataset:\n",
    "    def __init__(self, df, tfms):\n",
    "        self.df = df\n",
    "        self.tfms = tfms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.df.iloc[idx, :]\n",
    "        image_path = sample[\"image\"]\n",
    "        caption = sample[\"caption\"]\n",
    "\n",
    "        # Load and transform image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "        image = self.tfms(image=image)[\"image\"]\n",
    "\n",
    "        # Process caption\n",
    "        caption = f\"{caption} <|endoftext|>\"\n",
    "        input_ids = text_to_ids(caption)\n",
    "        labels = input_ids.copy()\n",
    "        labels[:-1] = input_ids[1:]\n",
    "\n",
    "        return image, input_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = [i[0] for i in batch]\n",
    "    input_ids = [i[1] for i in batch]\n",
    "    labels = [i[2] for i in batch]\n",
    "\n",
    "    images = torch.stack(images, dim=0)\n",
    "    max_len = max(len(seq) for seq in input_ids)\n",
    "\n",
    "    # Padding\n",
    "    input_ids_padded = torch.full((len(batch), max_len), fill_value=0, dtype=torch.long)\n",
    "    labels_padded = torch.full((len(batch), max_len), fill_value=-100, dtype=torch.long)\n",
    "\n",
    "    for i, (inp, lbl) in enumerate(zip(input_ids, labels)):\n",
    "        input_ids_padded[i, : len(inp)] = torch.tensor(inp, dtype=torch.long)\n",
    "        labels_padded[i, : len(lbl)] = torch.tensor(lbl, dtype=torch.long)\n",
    "\n",
    "    return images, input_ids_padded, labels_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ict\\.venv\\Lib\\site-packages\\albumentations\\core\\validation.py:58: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\TechMadmin\\AppData\\Local\\Temp\\ipykernel_12676\\27032829.py:17: UserWarning: Argument(s) 'always_apply' are not valid for transform Normalize\n",
      "  A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], always_apply=True),\n"
     ]
    }
   ],
   "source": [
    "caption_path = \"D:/ict/Data/fl8telugu.txt\"\n",
    "telugu_captions = load_telugu_captions(caption_path)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(\n",
    "    [{\"image\": f\"D:/ict/Data/Images/{img}\", \"caption\": caption} for img, captions in telugu_captions.items() for caption in captions]\n",
    ")\n",
    "\n",
    "# Define Transformations\n",
    "train_tfms = A.Compose([\n",
    "    A.HorizontalFlip(),\n",
    "    A.RandomBrightnessContrast(),\n",
    "    A.ColorJitter(),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.3, rotate_limit=45, p=0.5),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], always_apply=True),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Telugu Captions:                        image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0  గులాబీ రంగు దుస్తులు ధరించిన పిల్లవాడు ప్రవేశ ...  \n",
      "1               ఒక చెక్క భవనంలోకి వెళుతున్న అమ్మాయి.  \n",
      "2       ఒక చిన్న అమ్మాయి చెక్క ప్లేహౌస్ పైకి ఎక్కడం.  \n",
      "3     ఒక చిన్న అమ్మాయి తన ప్లేహౌస్కు మెట్లు ఎక్కేది.  \n",
      "4  గులాబీ రంగు దుస్తులు ధరించిన ఒక చిన్న అమ్మాయి ...  \n"
     ]
    }
   ],
   "source": [
    "telugu_captions = load_telugu_captions(\"D:/ict/Data/fl8telugu.txt\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(\n",
    "    [{\"image\": img, \"caption\": caption} for img, captions in telugu_captions.items() for caption in captions]\n",
    ")\n",
    "\n",
    "print(\"Loaded Telugu Captions:\", df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1000268201_693b08cb0e.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[39m=\u001b[39m TeluguDataset(df, train_tfms)\n\u001b[0;32m      3\u001b[0m \u001b[39m# Test Preprocessing\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m sample_image, sample_input_ids, sample_labels \u001b[39m=\u001b[39m dataset[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSample Image Shape:\u001b[39m\u001b[39m\"\u001b[39m, sample_image\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSample Token IDs:\u001b[39m\u001b[39m\"\u001b[39m, sample_input_ids)\n",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m, in \u001b[0;36mTeluguDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     12\u001b[0m caption \u001b[39m=\u001b[39m sample[\u001b[39m\"\u001b[39m\u001b[39mcaption\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     14\u001b[0m \u001b[39m# Load and transform image\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(image_path)\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(image)\n\u001b[0;32m     17\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfms(image\u001b[39m=\u001b[39mimage)[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\ict\\.venv\\Lib\\site-packages\\PIL\\Image.py:3465\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3462\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(fp)\n\u001b[0;32m   3464\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3465\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3466\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3467\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1000268201_693b08cb0e.jpg'"
     ]
    }
   ],
   "source": [
    "dataset = TeluguDataset(df, train_tfms)\n",
    "\n",
    "# Test Preprocessing\n",
    "sample_image, sample_input_ids, sample_labels = dataset[0]\n",
    "\n",
    "print(\"Sample Image Shape:\", sample_image.shape)\n",
    "print(\"Sample Token IDs:\", sample_input_ids)\n",
    "print(\"Sample Labels:\", sample_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
